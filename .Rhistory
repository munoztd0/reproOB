### Linear Mixed Models
# Mixed is just a wrapper for lmer to get p-values from parametric bootstrapping #but set to method "LRT" and remove "args_test" to quick check ##
#model = mixed(formula, data = PAV.clean, method = "LRT", control = control, REML = FALSE);
#model = mixed(formula, data = PAV.clean, method = "PB", control = control, REML = FALSE, args_test = list(nsim = 10, cl=cl));
model = aov_car(RT ~ condition*group + age + gender + thirsty + hungry +
Error(id/condition), PAV.means, factorize = F, anova_table = list(correction = "GG", es = "none"))
table = nice(model);
#calculate Partial eta-squared and its 90 % CI for each effect
pes_CI = pes_ci(RT ~ condition*group + age + gender + thirsty + hungry +
Error(id/condition), PAV.means);
table$`PES` = pes_CI[,1]
table$`Lower CI` = pes_CI[,2]
table$`Upper CI` = pes_CI[,3]
#calculate exclusion BF01 for each effect
test = extractBF(generalTestBF(RT ~ condition*group + condition*age + condition*gender + condition*thirsty + condition*hungry + id, data= PAV.means, whichRandom = 'id', neverExclude =  'id', whichModels ="top")); BF = 1/test[1] #switch to BF10 inclusion)); BF = 1/test[1] #switch to BF10 inclusion
table$BF10 = BF$bf[order(c(11,10,9,8,7,5,4,3,2,1,6))] # reorder
mod <- lmer(RT ~ condition*group + condition*age + condition*gender + condition*thirsty + condition*hungry + (condition|id), data = PAV.clean, control = control, REML = T) # recompute model with REML = T now for further report
ref_grid(model)  #triple check everything is centered at 0
tab_model(mod, show.p = F,show.intercept = F, show.se = T, title ="", show.re.var = F, digits = 3, dv.labels = "Reaction Times", emph.p = TRUE, file = "tmp/temp1.html")#pred.labels=c("CS+", "Lean", "Interaction (Lean:CS+)")
tables <- list.clean(readHTMLTable("tmp/temp1.html"), fun = is.null, recursive = FALSE)
tables2 = tables[[1]] %>% janitor::row_to_names(row_number = 1)
tables2 <- as.matrix(tables2) %>% as_tibble()
tables2[is.na(tables2)] <- ""
tables2[1:11,1:4] %>% kbl(caption ="Reaction Times" ) %>%
kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%  row_spec(0,bold=T,align='c')
tmp =tables2[12:15,1:2]
names(tmp) <- NULL
tmp %>% kbl() %>%
kable_styling(latex_options = "HOLD_position", position = "center", full_width = F)
table %>% kbl(digits = 2) %>%
kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%  row_spec(0,bold=T,align='c')
#Estimated contrast mean and 95% CI\ (one sided test  side = "<")
#p_cond = emmeans(mod, pairwise~ condition, side = "<"); p_cond #for condition (CS+ < CS- left sided!)
#CI_cond = confint(emmeans(mod, pairwise~ condition),level = 0.95, method = c("boot"), nsim = 5000);
#tab =as_tibble(CI_cond$contrasts); tab$contrast = "CS+ > CS-"
#tab %>% kbl() %>%
#kable_styling(latex_options = "striped", position = "left", full_width = F)
# RT
dfR <- summarySEwithin(PAV.means,
measurevar = "RT",
withinvars = "condition",
idvar = "id")
dfR$cond <- ifelse(dfR$condition == "1", -0.25, 0.25)
PAV.means$cond <- ifelse(PAV.means$condition == "1", -0.25, 0.25)
PAV.means <- PAV.means %>% mutate(condjit = jitter(as.numeric(cond), 0.3),
grouping = interaction(id, cond))
pp <- ggplot(PAV.means, aes(x = cond, y = RT,
fill = condition, color = condition)) +
geom_line(aes(x = condjit, group = id, y = RT), alpha = .3, size = 0.5, color = 'gray') +
geom_flat_violin(scale = "count", trim = FALSE, alpha = .2, aes(fill = condition, color = NA))+
geom_point(aes(x = condjit, shape = group), alpha = .3,) +
geom_crossbar(data = dfR, aes(y = RT, ymin=RT-se, ymax=RT+se), width = 0.2 , alpha = 0.1)+
ylab('Reaction Times (ms)')+
xlab('Conditioned stimulus')+
scale_y_continuous(expand = c(0, 0), breaks = c(seq.int(200,800, by = 200)), limits = c(180,875)) +
scale_x_continuous(labels=c("CS+", "CS-"),breaks = c(-.25,.25), limits = c(-.5,.5)) +
scale_fill_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
scale_color_manual(values=c("1"= pal[2], "-1"=  pal[1]), guide = 'none') +
scale_shape_manual(name="Group", labels=c("Lean", "Obese"), values = c(1, 2)) +
theme_bw()
plt = pp + averaged_theme
pp + html_theme
cairo_pdf('figures/Figure_PavlovianRT.pdf')
print(plt)
dev.off()
# -------------------------------------- Liking
# Mixed is just a wrapper for lmer to get p-values from parametric bootstrapping #but set to method "LRT" and remove "args_test" to quick check ##
#model = mixed(formula, data = PAV.means, method = "LRT", control = control, REML = FALSE);
model = aov_car(liking ~ condition + group + age + gender + thirsty + hungry + Error(id/condition), data= PAV.means, factorize = F, anova_table = list(correction = "GG", es = "none"))
table = nice(model);
#calculate Partial eta-squared and its 90 % CI for each effect
pes_CI = pes_ci(liking ~ condition*group + age + gender + thirsty + hungry + Error(id/condition), PAV.means);
table$`PES` = pes_CI[,1]
table$`Lower CI` = pes_CI[,2]
table$`Upper CI` = pes_CI[,3]
#calculate exclusion BF01 for each effect
test = extractBF(generalTestBF(liking ~ condition*group + condition*age + condition*gender + condition*thirsty + condition*hungry + id, data= PAV.means, whichRandom = 'id', neverExclude =  'id', whichModels ="top")); BF = 1/test[1] #switch to BF10 inclusion)); BF = 1/test[1] #switch to BF10 inclusion
table$BF10 = BF$bf[order(c(11,10,9,8,7,5,4,3,2,1,6))] # reorder
mod <- lm(liking ~ condition*group + condition*age + condition*gender + condition*thirsty + condition*hungry , data = PAV.means) # for estimated means
ref_grid(model)  #triple check everything is centered at 0
tab_model(mod, show.p = F,show.intercept = F, show.se = T,  title ="", show.re.var = F, digits = 3, dv.labels = "Pleasantness Ratings (Pavlovian Cue)", emph.p = TRUE, file = "tmp/temp2.html")#pred.labels=c("CS+", "Lean", "Interaction (Lean:CS+)")
table$BF10 = round(BF$bf[order(c(11,10,9,8,7,5,4,3,2,1,6))],2) # reorder
table$BF10[6] = formatC(BF$bf[11], format = "e", digits = 2)
table
knitr::opts_chunk$set(echo = FALSE, warnings=FALSE)
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
info <- automate_load_data(info, read.csv, stringsAsFactors = T)
knitr::opts_chunk$set(echo = FALSE, warnings=FALSE)
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
info <- automate_load_data(info, read.csv, stringsAsFactors = T)
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
PAV <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED <- automate_load_data(HED, read.csv, stringsAsFactors = T)
x =HED %>% spread(session, perceived_liking)
View(x)
reshape(HED, idvar = "perceived_liking", timevar = "session", direction = "wide")
x =reshape(HED, idvar = "perceived_liking", timevar = "session", direction = "wide")
source('~/Desktop/SwitchDrive/LIRA/R/utils.R', echo=TRUE)
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)intreact(x))
list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
View(HED)
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)\
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
knitr::opts_chunk$set(echo = FALSE, warnings=FALSE)
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
info <- automate_load_data(info, read.csv, stringsAsFactors = T)
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
PAV <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED <- automate_load_data(HED, read.csv, stringsAsFactors = T)
check_git()
check_make()
check_docker()
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = parallel::detectCores()) #remove scientific notation # remove warnings #set contrasts to sum !
set.seed(666) #set random seed
control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb')) #set "better" lmer optimizer #nolimit # yoloptimizer
emm_options(pbkrtest.limit = 5000) #increase repetitions limit
cl <- parallel::detectCores() #to mulithread
source('R/plots.R', echo=F)# plot specification
source('R/utils.R', echo=F)# useful functions
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t1
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
#center covariates
numer <- c("thirsty", "hungry", "age", "diff_BMI")
tables <- c("PAV","INST","PIT","HED")
dflist <- lapply(mget(tables),function(x) x %>% group_by %>% mutate_at(numer, scale))
list2env(dflist, envir=.GlobalEnv)
#center covariates
numer <- c("thirsty", "hungry", "age", "diff_BMI", "BMI_t1")
dflist <- lapply(mget(tables),function(x) x %>% group_by %>% mutate_at(numer, scale))
list2env(dflist, envir=.GlobalEnv)
save(HED, "hed")
save(HED, "HED")
save('HED', HED)
save(HED, file = 'hed.Rdata')
save(PIT, file = 'pit.Rdata')
load("~/Desktop/SwitchDrive/LIRA/pit.Rdata")
View(PIT)
load("~/Desktop/SwitchDrive/LIRA/hed.Rdata")
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t1
data$diff_BMIz = data$BMI_t1 - data$BMI_t1
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
knitr::opts_chunk$set(echo = FALSE, warnings=FALSE)
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
info <- automate_load_data(info, read.csv, stringsAsFactors = T)
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
PAV <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED <- automate_load_data(HED, read.csv, stringsAsFactors = T)
check_git()
check_make()
check_docker()
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t1
data$diff_BMIz = data$BMI_t1 - data$BMI_t1
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
knitr::opts_chunk$set(echo = FALSE, warnings=FALSE)
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
info <- automate_load_data(info, read.csv, stringsAsFactors = T)
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
PAV <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED <- automate_load_data(HED, read.csv, stringsAsFactors = T)
check_git()
check_make()
check_docker()
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t1
data$diff_BMIz = data$BMI_t1 - data$BMI_t1
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t2
data$diff_BMIz = data$BMI_t1 - data$BMI_t2
return(data)
}
dflist = mapply(def,tables,listA)
knitr::opts_chunk$set(echo = FALSE, warnings=FALSE)
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
info <- automate_load_data(info, read.csv, stringsAsFactors = T)
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
PAV <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED <- automate_load_data(HED, read.csv, stringsAsFactors = T)
check_git()
check_make()
check_docker()
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
source('~/Desktop/SwitchDrive/LIRA/R/utils.R', echo=TRUE)
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t2
data$diff_BMIz = data$BMI_t1 - data$BMI_t2
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
data = merge(x = HED, y = INTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data = merge(x = HED, y = intern[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
View(data)
data = merge(x = PIT, y = intern[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data = merge(x = PAV, y = intern[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data = merge(x = INST, y = intern[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
knitr::opts_chunk$set(echo = FALSE, warnings=FALSE)
library(repro)
# load packages from yaml header
automate_load_packages()
# include external scripts
automate_load_scripts()
# load data
info <- automate_load_data(info, read.csv, stringsAsFactors = T)
intern <- automate_load_data(intern, read.csv, stringsAsFactors = T)
PAV <- automate_load_data(PAV, read.csv, stringsAsFactors = T)
INST <- automate_load_data(INST, read.csv, stringsAsFactors = T)
PIT <- automate_load_data(PIT, read.csv, stringsAsFactors = T)
HED <- automate_load_data(HED, read.csv, stringsAsFactors = T)
check_git()
check_make()
check_docker()
options(scipen = 666, warn=-1, contrasts=c("contr.sum","contr.poly"), mc.cores = parallel::detectCores()) #remove scientific notation # remove warnings #set contrasts to sum !
set.seed(666) #set random seed
control = lmerControl(optimizer ='optimx', optCtrl=list(method='nlminb')) #set "better" lmer optimizer #nolimit # yoloptimizer
emm_options(pbkrtest.limit = 5000) #increase repetitions limit
cl <- parallel::detectCores() #to mulithread
source('R/plots.R', echo=F)# plot specification
source('R/utils.R', echo=F)# useful functions
#----clean----
#subset only pretest
tables <- c("PAV","INST","PIT","HED", "intern")
dflist <- lapply(mget(tables),function(x)subset(x, group == 'obese'))
list2env(dflist, envir=.GlobalEnv)
#exclude participants (242 really outlier everywhere, 256 can't do the task, 114 & 228 REALLY hated the solution and thus didn't "do" the conditioning) & 123 and 124 have imcomplete data
# `%notin%` <- Negate(`%in%`)
# dflist <- lapply(mget(tables),function(x)filter(x, id %notin% c(242, 256, 114, 228, 123, 124)))
# list2env(dflist, envir=.GlobalEnv)
#create idXsession
dflist <- lapply(mget(tables),function(x)interact(x))
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables = tables[-length(tables)] # remove intern
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'idXsession')], by = "idXsession", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t2
data$diff_BMIz = data$BMI_t1 - data$BMI_t2
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
x =spread(HED, session, pleasantness_ratings, fill = NA, convert = FALSE, drop = TRUE, sep = NULL)
x =spread(HED, session, perceived_liking, fill = NA, convert = FALSE, drop = TRUE, sep = NULL)
View(x)
df = HED[-c('idXsession')]
head(HED)\
head(HED)
df = HED[-c(1)]
x =spread(df, session, perceived_liking, fill = NA, convert = FALSE, drop = TRUE, sep = NULL)
HED
x =df %>% gather(session, perceived_liking, -(perceived_liking:perceived_intensity)) %>%
unite(id, gender, session) %>%
spread(id, perceived_liking)
df %>% gather(session, perceived_liking, -(perceived_liking:perceived_intensity)) %>%
unite(id, session) %>%
spread(id, perceived_liking)
x =df %>% gather(session, perceived_liking, -(perceived_liking:perceived_intensity)) %>%
unite(id, session) %>%
spread(id, perceived_liking)
View(x)
x =spread(df, c(session,id), perceived_liking, fill = NA, convert = FALSE, drop = TRUE, sep = NULL)
x =spread(df, c(id), perceived_liking, fill = NA, convert = FALSE, drop = TRUE, sep = NULL)
View(x)
x = df %>%
gather(session,perceived_liking) %>%
spread(id,perceived_liking)
df %>%
gather(session,perceived_liking) %>%
spread(session,perceived_liking)
x =spread(df, c(id), perceived_liking, fill = NA, convert = FALSE, drop = FALSE, sep = NULL)
View(df)
x = df %>% mutate(i = row_number()) %>% spread(session, id)
View(x)
x = df %>% mutate(i = row_number()) %>% spread(session, perceived_liking)
View(x)
PIT.means <- aggregate(PIT.clean$RT, by = list(PIT.clean$id,PIT.clean$idXsession, PIT.clean$condition, PIT.clean$session, PIT.clean$intervention, PIT.clean$age, PIT.clean$gender, PIT.clean$thirsty,PIT.clean$hungry), FUN='mean') # extract means
colnames(PIT.means) <- c('id', 'idXsession', 'condition','session', 'age','gender', 'thirsty', 'hungry', 'RT')
PIT.means <- aggregate(PIT$RT, by = list(PIT$id,PIT$idXsession, PIT$condition, PIT$session, PIT$intervention, PIT$age, PIT$gender, PIT$thirsty,PIT$hungry), FUN='mean') # extract means
colnames(PIT.means) <- c('id', 'idXsession', 'condition','session', 'age','gender', 'thirsty', 'hungry', 'RT')
PIT.means <- aggregate(PIT$AUC, by = list(PIT$id,PIT$idXsession, PIT$condition, PIT$session, PIT$intervention, PIT$age, PIT$gender, PIT$thirsty,PIT$hungry), FUN='mean') # extract means
colnames(PIT.means) <- c('id', 'idXsession', 'condition','session', 'age','gender', 'thirsty', 'hungry', 'AUC')
View(PIT.means)
PIT.means <- aggregate(PIT$AUC, by = list(PIT$id, PIT$condition, PIT$session, PIT$intervention, PIT$age, PIT$gender, PIT$thirsty,PIT$hungry), FUN='mean') # extract means
colnames(PIT.means) <- c('id', 'condition','session', 'age','gender', 'thirsty', 'hungry', 'AUC')
x =spread(PIT.means, session, AUC)
PIT.means <- aggregate(PIT$AUC, by = list(PIT$id, PIT$condition, PIT$session, PIT$intervention, PIT$age, PIT$gender, PIT$thirsty,PIT$hungry), FUN='mean') # extract means
colnames(PIT.means) <- c('id', 'condition','session', 'interventiin', 'age','gender', 'thirsty', 'hungry', 'AUC')
x =spread(PIT.means, session, AUC)
View(x)
PIT.means <- aggregate(PIT$AUC, by = list(PIT$id, PIT$condition, PIT$session, PIT$intervention), FUN='mean') # extract means
colnames(PIT.means) <- c('id', 'condition','session', 'interventiin', 'AUC')
x =spread(PIT.means, session, AUC)
View(intern)
tables <- c("PIT.means")
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
listA = 2
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t2
data$diff_BMIz = data$BMI_t1 - data$BMI_t2
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
#merge with info
tables <- c("PIT.means", "PIT.means", "PIT.means", "PIT.means", "PIT.means")
dflist <- lapply(mget(tables),function(x)merge(x, info, by = "id"))
list2env(dflist, envir=.GlobalEnv)
# creates internal states variables for each data
listA = 2:5
def = function(data, number){
baseINTERN = subset(intern, phase == number)
data = merge(x = get(data), y = baseINTERN[ , c("thirsty", 'hungry', 'id')], by = "id", all.x=TRUE)
data$diff_BMI = data$BMI_t1 - data$BMI_t2
data$diff_BMIz = data$BMI_t1 - data$BMI_t2
return(data)
}
dflist = mapply(def,tables,listA)
list2env(dflist, envir=.GlobalEnv)
